{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "371fe5a17b7148fcb65efe77d26eb60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e0e62cff5a641a1863bd4cc7f280e98",
              "IPY_MODEL_f2d356fd7a1442cd90347d5fdb179bc5",
              "IPY_MODEL_62eb5d778ef440028f0f7e29a04154c7"
            ],
            "layout": "IPY_MODEL_ee37fe37e2594e1f9bd8393ebad7f522"
          }
        },
        "6e0e62cff5a641a1863bd4cc7f280e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73423ce91c4249619f3bf2eaee454d43",
            "placeholder": "​",
            "style": "IPY_MODEL_0535f0e6637444fbae3369f7123b93fe",
            "value": "Downloading config.json: 100%"
          }
        },
        "f2d356fd7a1442cd90347d5fdb179bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11baa9287b764c679dd85e85b028feeb",
            "max": 440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_713e1b32e55442daa5e2c9ab2bd9b0f1",
            "value": 440
          }
        },
        "62eb5d778ef440028f0f7e29a04154c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_296da34e44be471b8684df9d6cfebf0e",
            "placeholder": "​",
            "style": "IPY_MODEL_e9020b59a7ab48c6966761b77b3bcadd",
            "value": " 440/440 [00:00&lt;00:00, 11.2kB/s]"
          }
        },
        "ee37fe37e2594e1f9bd8393ebad7f522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73423ce91c4249619f3bf2eaee454d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0535f0e6637444fbae3369f7123b93fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11baa9287b764c679dd85e85b028feeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713e1b32e55442daa5e2c9ab2bd9b0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "296da34e44be471b8684df9d6cfebf0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9020b59a7ab48c6966761b77b3bcadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b5164ff29a4c7f958f434084c821cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d903e7f1de14b0eae7d64b5289016dc",
              "IPY_MODEL_4cfa88163103451fb4c74d03a98f6fe0",
              "IPY_MODEL_98722d9aebe247ae9cc1824e39238e86"
            ],
            "layout": "IPY_MODEL_079bb681605d44e9878d9fa508c3d242"
          }
        },
        "1d903e7f1de14b0eae7d64b5289016dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9c1929a295c4bfc900127d04bf6d6dd",
            "placeholder": "​",
            "style": "IPY_MODEL_8a45bd53c2494f40ba2627feec3d409c",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "4cfa88163103451fb4c74d03a98f6fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a16eba153c78418282f0bc637edd0ae4",
            "max": 1198122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c28b6cc2e1ac4dbf88384c0e079f1b02",
            "value": 1198122
          }
        },
        "98722d9aebe247ae9cc1824e39238e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99dc172d75474a63bb5744e0041afe5f",
            "placeholder": "​",
            "style": "IPY_MODEL_0aea53a299354ad89d88111c8eabbb12",
            "value": " 1.14M/1.14M [00:01&lt;00:00, 968kB/s]"
          }
        },
        "079bb681605d44e9878d9fa508c3d242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c1929a295c4bfc900127d04bf6d6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a45bd53c2494f40ba2627feec3d409c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16eba153c78418282f0bc637edd0ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c28b6cc2e1ac4dbf88384c0e079f1b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99dc172d75474a63bb5744e0041afe5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aea53a299354ad89d88111c8eabbb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate models on testset"
      ],
      "metadata": {
        "id": "uBNWscSLK5_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq72QT_kKyIt",
        "outputId": "da91d9e2-1eab-45df-d26d-dfeffebba18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets\n",
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZlX2U4EVATI",
        "outputId": "afb60dd3-91f2-41c2-9dc7-2f648e748c9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 365 kB 34.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 73.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 68.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 141 kB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 35.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_from_disk, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "model_checkpoint = \"HooshvareLab/bert-fa-base-uncased\"\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/PQA/\"\n",
        "max_length = 512 # The maximum length of a feature (question and context)\n",
        "doc_stride = 256 # The authorized overlap between two part of the context when splitting it is needed."
      ],
      "metadata": {
        "id": "618rOPEDVZm5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and prepare Test set"
      ],
      "metadata": {
        "id": "Wg-WTl4PaRV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_train_features(examples):\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,)\n",
        "    \n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "id": "wM3q_RIrVlF4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = load_from_disk(DRIVE_PATH + \"test.hf\").shuffle(seed=42)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenized_test = test_dataset.map(prepare_train_features, batched=True, remove_columns=test_dataset.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "371fe5a17b7148fcb65efe77d26eb60b",
            "6e0e62cff5a641a1863bd4cc7f280e98",
            "f2d356fd7a1442cd90347d5fdb179bc5",
            "62eb5d778ef440028f0f7e29a04154c7",
            "ee37fe37e2594e1f9bd8393ebad7f522",
            "73423ce91c4249619f3bf2eaee454d43",
            "0535f0e6637444fbae3369f7123b93fe",
            "11baa9287b764c679dd85e85b028feeb",
            "713e1b32e55442daa5e2c9ab2bd9b0f1",
            "296da34e44be471b8684df9d6cfebf0e",
            "e9020b59a7ab48c6966761b77b3bcadd",
            "c7b5164ff29a4c7f958f434084c821cf",
            "1d903e7f1de14b0eae7d64b5289016dc",
            "4cfa88163103451fb4c74d03a98f6fe0",
            "98722d9aebe247ae9cc1824e39238e86",
            "079bb681605d44e9878d9fa508c3d242",
            "f9c1929a295c4bfc900127d04bf6d6dd",
            "8a45bd53c2494f40ba2627feec3d409c",
            "a16eba153c78418282f0bc637edd0ae4",
            "c28b6cc2e1ac4dbf88384c0e079f1b02",
            "99dc172d75474a63bb5744e0041afe5f",
            "0aea53a299354ad89d88111c8eabbb12"
          ]
        },
        "id": "1UJ7iK41VTz4",
        "outputId": "06ec7f5e-8b33-41e4-c434-aa00591ee956"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /content/drive/MyDrive/PQA/test.hf/cache-f300ebb919f7a933.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "371fe5a17b7148fcb65efe77d26eb60b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7b5164ff29a4c7f958f434084c821cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /content/drive/MyDrive/PQA/test.hf/cache-4c5ac2a496ecbe27.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pars BERT model"
      ],
      "metadata": {
        "id": "_1nc6kb4aaKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = \"/content/drive/MyDrive/PQA/\"\n",
        "model_path = DRIVE_PATH + f\"checkpoints/checkpoint-2548/\"  ## load model trained for 2 epochs\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "2KBZjvX1WYYw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Class"
      ],
      "metadata": {
        "id": "HDvijV8JaelA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AnswerPredictor:\n",
        "  def __init__(self, model, tokenizer, device='cuda', n_best=10, max_length=512, stride=256, no_answer=False):\n",
        "      \"\"\"Initializes PyTorch Question Answering Prediction\n",
        "      It's best to leave use the default values.\n",
        "      Args:\n",
        "          model: Fine-tuned torch model\n",
        "          tokenizer: Transformers tokenizer\n",
        "          device (torch.device): Running device\n",
        "          n_best (int): Number of best possible answers\n",
        "          max_length (int): Tokenizer max length\n",
        "          stride (int): Tokenizer stride\n",
        "          no_answer (bool): If True, model can return \"no answer\"\n",
        "      \"\"\"\n",
        "      self.model = model.eval().to(device)\n",
        "      self.tokenizer = tokenizer\n",
        "      self.device = device\n",
        "      self.max_length = max_length\n",
        "      self.stride = stride\n",
        "      self.no_answer = no_answer\n",
        "      self.n_best = n_best\n",
        "\n",
        "\n",
        "  def model_pred(self, questions, contexts, batch_size=1):\n",
        "      n = len(contexts)\n",
        "      if n%batch_size!=0:\n",
        "          raise Exception(\"batch_size must be divisible by sample length\")\n",
        "\n",
        "      tokens = self.tokenizer(questions, contexts, add_special_tokens=True, \n",
        "                              return_token_type_ids=True, return_tensors=\"pt\", padding=True, \n",
        "                              return_offsets_mapping=True, truncation=\"only_second\", \n",
        "                              max_length=self.max_length, stride=self.stride)\n",
        "\n",
        "      start_logits, end_logits = [], []\n",
        "      for i in tqdm(range(0, n-batch_size+1, batch_size)):\n",
        "          with torch.no_grad():\n",
        "              out = self.model(tokens['input_ids'][i:i+batch_size].to(self.device), \n",
        "                          tokens['attention_mask'][i:i+batch_size].to(self.device), \n",
        "                          tokens['token_type_ids'][i:i+batch_size].to(self.device))\n",
        "\n",
        "              start_logits.append(out.start_logits)\n",
        "              end_logits.append(out.end_logits)\n",
        "\n",
        "      return tokens, torch.stack(start_logits).view(n, -1), torch.stack(end_logits).view(n, -1)\n",
        "\n",
        "\n",
        "  def __call__(self, questions, contexts, batch_size=1, answer_max_len=100):\n",
        "      \"\"\"Creates model prediction\n",
        "      \n",
        "      Args: \n",
        "          questions (list): Question strings\n",
        "          contexts (list): Contexts strings\n",
        "          batch_size (int): Batch size\n",
        "          answer_max_len (int): Sets the longests possible length for any answer\n",
        "        \n",
        "      Returns:\n",
        "          dict: The best prediction of the model\n",
        "              (e.g {0: {\"text\": str, \"score\": int}})\n",
        "      \"\"\"\n",
        "      tokens, starts, ends = self.model_pred(questions, contexts, batch_size=batch_size)\n",
        "      start_indexes = starts.argsort(dim=-1, descending=True)[:, :self.n_best]\n",
        "      end_indexes = ends.argsort(dim=-1, descending=True)[:, :self.n_best]\n",
        "\n",
        "      preds = {}\n",
        "      for i, (c, q) in enumerate(zip(contexts, questions)):  \n",
        "          min_null_score = starts[i][0] + ends[i][0] # 0 is CLS Token\n",
        "          start_context = tokens['input_ids'][i].tolist().index(self.tokenizer.sep_token_id)\n",
        "          \n",
        "          offset = tokens['offset_mapping'][i]\n",
        "          valid_answers = []\n",
        "          for start_index in start_indexes[i]:\n",
        "              # Don't consider answers that are in questions\n",
        "              if start_index<start_context:\n",
        "                  continue\n",
        "              for end_index in end_indexes[i]:\n",
        "                  # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                  # to part of the input_ids that are not in the context.\n",
        "                  if (start_index >= len(offset) or end_index >= len(offset)\n",
        "                      or offset[start_index] is None or offset[end_index] is None):\n",
        "                      continue\n",
        "                  # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                  if end_index < start_index or (end_index-start_index+1) > answer_max_len:\n",
        "                      continue\n",
        "\n",
        "                  start_char = offset[start_index][0]\n",
        "                  end_char = offset[end_index][1]\n",
        "                  valid_answers.append({\"score\": (starts[i][start_index] + ends[i][end_index]).item(),\n",
        "                                        \"text\": c[start_char: end_char]})\n",
        "                  \n",
        "          if len(valid_answers) > 0:\n",
        "              best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "          else:\n",
        "              best_answer = {\"text\": \"\", \"score\": min_null_score}\n",
        "\n",
        "          if self.no_answer:\n",
        "              preds[i] = best_answer if best_answer[\"score\"] >= min_null_score else {\"text\": \"\", \"score\": min_null_score}\n",
        "          else:\n",
        "              preds[i] = best_answer\n",
        "\n",
        "      return preds\n"
      ],
      "metadata": {
        "id": "2VGmFe8AWas6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EM and F1 "
      ],
      "metadata": {
        "id": "078NSxVOag-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_f1(prediction, answer):\n",
        "    pred_tokens = prediction.split()\n",
        "    answer_tokens = answer.split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(answer_tokens) == 0:\n",
        "        return int(pred_tokens == answer_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(answer_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(answer_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def compute_exact_match(prediction, answer):\n",
        "    return int(prediction == answer)"
      ],
      "metadata": {
        "id": "MrkQ-MJ9Wx2Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "P4-96G3wamBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = AnswerPredictor(model, tokenizer, device='cuda', n_best=10, no_answer=True)\n",
        "\n",
        "EH = 0\n",
        "F1 = 0\n",
        "\n",
        "for example in test_dataset: \n",
        "\n",
        "  #print(len(example['answers']))\n",
        "  #if len(example['answers']) != 2: \n",
        "    #print(example['answers'])\n",
        "  if example['answers']['text'] == [] :\n",
        "    context = example['context'] \n",
        "    question = example['question'] \n",
        "    preds = predictor([question], [context], batch_size=1)\n",
        "    pred = preds[0]['text'].strip()\n",
        "    if pred == [] : \n",
        "      EH += 1\n",
        "      F1 += 1\n",
        "\n",
        "    continue\n",
        "\n",
        "  context = example['context'] \n",
        "  question = example['question'] \n",
        "  answer = example['answers']['text'][0]\n",
        "  preds = predictor([question], [context], batch_size=1)\n",
        "  pred = preds[0]['text'].strip()\n",
        "\n",
        "  EH += compute_exact_match(pred, answer)\n",
        "  F1 += compute_f1(pred, answer)\n",
        "\n",
        "EH /= len(test_dataset)\n",
        "F1 /= len(test_dataset)"
      ],
      "metadata": {
        "id": "vqqFef7ZW1ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Exact match of Pars BERT on testset : ' + str(EH))\n",
        "print('F1 score of Pars BERT on testset : ' + str(F1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4lDEg0Scz_Q",
        "outputId": "fec6a1b1-1816-477f-e01d-8657a96c676e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact match of Pars BERT on testset : 0.1896853146853147\n",
            "F1 score of Pars BERT on testset : 0.3427832896026578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation of ParsT5"
      ],
      "metadata": {
        "id": "oyzFHwIQLvyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 1Lcs5eGTIhy0JUY9FW2pn-80m3CHyVtvQ\n",
        "! unzip ParsT5.zip\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "TH-VTc5ULvIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "model_path = '/content/content/drive/MyDrive/parsT5_QA/model_4'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "ymSuoRLKMNkB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EH = 0\n",
        "F1 = 0\n",
        "\n",
        "cnt = 0 \n",
        "for example in test_dataset: \n",
        "\n",
        "  cnt += 1\n",
        "  print(cnt)\n",
        "\n",
        "  context = example['context'] \n",
        "  question = example['question']\n",
        "  input = 'متن: ' + context + '، پرسش: ' + question\n",
        "  input_ids = tokenizer.encode(input, return_tensors='pt')\n",
        "  output_ids = model.generate(input_ids, max_length=150, num_beams=2, repetition_penalty=2.5, length_penalty=1.0, early_stopping=True)\n",
        "  output = ' '.join([tokenizer.decode(id) for id in output_ids])\n",
        "  pred = output.replace('<pad>', '').replace('</s>', '').strip()\n",
        "\n",
        "  \n",
        "  if example['answers']['text'] == [] :\n",
        "    if pred == 'بدون پاسخ' : \n",
        "      EH += 1\n",
        "      F1 += 1\n",
        "    continue\n",
        "\n",
        "  answer = example['answers']['text'][0]\n",
        "\n",
        "\n",
        "  EH += compute_exact_match(pred, answer)\n",
        "  F1 += compute_f1(pred, answer)\n",
        "\n",
        "EH /= len(test_dataset)\n",
        "F1 /= len(test_dataset)"
      ],
      "metadata": {
        "id": "ZnPY4taiMRrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Exact match of Pars BERT on testset : ' + str(EH))\n",
        "print('F1 score of Pars BERT on testset : ' + str(F1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6ovVSKJPsO1",
        "outputId": "05cdd3ef-9105-4869-b052-a1c415d64be2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact match of Pars BERT on testset : 0.3173076923076923\n",
            "F1 score of Pars BERT on testset : 0.38419642354479394\n"
          ]
        }
      ]
    }
  ]
}
